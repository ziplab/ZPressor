# First, train it on RealEstate10K
python -m src.main +experiment=re10k \
data_loader.train.batch_size=1 \
'dataset.roots'='["datasets/re10k"]' \
'dataset.image_shape'='[256,448]' \
dataset.test_chunk_interval=10 \
dataset.near=1. \
dataset.far=200. \
dataset.view_sampler.num_context_views=12 \
dataset.view_sampler.num_target_views=8 \
dataset.view_sampler.min_distance_between_context_views=50 \
dataset.view_sampler.max_distance_between_context_views=200 \
dataset.view_sampler.context_gap_warm_up_steps=10000 \
dataset.view_sampler.initial_min_distance_between_context_views=15 \
dataset.view_sampler.initial_max_distance_between_context_views=50 \
trainer.val_check_interval=0.2 \
trainer.max_steps=100000 \
train.eval_data_length=150 \
train.eval_model_every_n_val=3 \
model.encoder.upsample_factor=8 \
model.encoder.lowest_feature_resolution=8 \
model.encoder.monodepth_vit_type=vitb \
model.encoder.gaussian_regressor_channels=32 \
model.encoder.color_large_unet=true \
model.encoder.feature_upsampler_channels=128 \
model.encoder.multiview_trans_nearest_n_views=3 \
model.encoder.costvolume_nearest_n_views=3 \
model.encoder.return_depth=true \
model.encoder.use_cluster=true \
model.encoder.cluster_num=6 \
model.encoder.apply_cluster_steps=0 \
model.encoder.no_self_attn=false \
model.encoder.use_clstoken=false  \
checkpointing.pretrained_monodepth=pretrained/depth_anything_v2_vitb.pth \
checkpointing.pretrained_mvdepth=pretrained/gmflow-scale1-things-e9887eda.pth \
wandb.project=depthsplat \
output_dir=checkpoints/depthsplat-re10k-zpressor-n200-256x448

# After move the pretrained model to the correct path (pretrained/depthsplat-re10k-zpressor-n200-256x448.ckpt), finetune it on DL3DV
python -m src.main +experiment=dl3dv \
data_loader.train.batch_size=1 \
'dataset.roots'='["datasets/dl3dv"]' \
'dataset.image_shape'='[256,448]' \
dataset.test_chunk_interval=10 \
dataset.near=1. \
dataset.far=200. \
dataset.view_sampler.num_context_views=12 \
dataset.view_sampler.num_target_views=8 \
dataset.view_sampler.min_distance_between_context_views=20 \
dataset.view_sampler.max_distance_between_context_views=50 \
dataset.view_sampler.context_gap_warm_up_steps=10000 \
dataset.view_sampler.initial_min_distance_between_context_views=15 \
dataset.view_sampler.initial_max_distance_between_context_views=30 \
trainer.val_check_interval=0.2 \
trainer.max_steps=100000 \
train.eval_data_length=150 \
train.eval_model_every_n_val=3 \
model.encoder.upsample_factor=8 \
model.encoder.lowest_feature_resolution=8 \
model.encoder.monodepth_vit_type=vitb \
model.encoder.gaussian_regressor_channels=32 \
model.encoder.color_large_unet=true \
model.encoder.feature_upsampler_channels=128 \
model.encoder.multiview_trans_nearest_n_views=3 \
model.encoder.costvolume_nearest_n_views=3 \
model.encoder.return_depth=true \
model.encoder.use_cluster=true \
model.encoder.cluster_num=6 \
model.encoder.apply_cluster_steps=0 \
model.encoder.no_self_attn=false \
model.encoder.use_clstoken=false  \
checkpointing.pretrained_model=pretrained/depthsplat-re10k-zpressor-n200-256x448.ckpt \
wandb.project=depthsplat \
output_dir=checkpoints/depthsplat-dl3dv-zpressor-n50-256x448